{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vsKjuyh-PT2d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "import torch.optim as optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "48000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hype-parameters\n",
    "num_epochs = 4 # how many times we are running \n",
    "batch_size = 32 # \n",
    "learning_rate = .001 # \n",
    "\n",
    "mnist = datasets.MNIST(\n",
    "    root='./data', # where to store data\n",
    "    train=True, # tell the code it is training data\n",
    "    download=True, # download the data\n",
    "    transform=transforms.ToTensor() # transform dataset to tensor directly (no preprocessing)\n",
    ") # import data\n",
    "print(len(mnist))\n",
    "\n",
    "mnist_train, mnist_test = torch.utils.data.random_split(mnist, [0.8, .2]) # split data 80/20\n",
    "print(len(mnist_train))\n",
    "print(len(mnist_test)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# init dataloaders to load batches into model\n",
    "train_dl  = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True) \n",
    "\n",
    "test_dl   = torch.utils.data.DataLoader(mnist_test, batch_size=10000, shuffle=False ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to measure accuracy, confusion matrix, precision, recall ,f1 (metrics to measure classification)\n",
    "def print_metrics_function(y_test, y_pred):\n",
    "    print('Accuracy: %.6f' % accuracy_score(y_test, y_pred))\n",
    "    confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confmat)\n",
    "    print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    f1_measure = f1_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "    print('F1-mesure: %.3f' % f1_measure)\n",
    "    return f1_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier6(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            ## Convolitional Layer 1\n",
    "                nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=1), # 1 input 16 filters, padding so same dim\n",
    "                nn.ReLU(), # ReLU introduce non-linearity\n",
    "                nn.MaxPool2d(2, 2), #pool\n",
    " \n",
    "                ## Convolutional Layer 2\n",
    "                nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=1), # 16 inputs 32 filters\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2, 2),   \n",
    " \n",
    "                ## feed forward layer w/ 1024 neurons, regular layer\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(800, 1024),    ## see how to get 800 below on last cell\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Linear(1024, 10), # maps to output w/ 10 classes\n",
    "                nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "   \n",
    "    def forward(self, inputs):\n",
    "        return self.model(inputs)\n",
    "        \n",
    "def training_loop( num_epochs, model, loss_fn, opt):\n",
    "\n",
    "    losses_list = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            \n",
    "            ## print( xb.shape )   ## check this comes out as [N, 1, 28, 28]\n",
    "            ## yb = torch.squeeze(yb, dim=1)\n",
    "            \n",
    "            y_pred = model(xb)\n",
    "            loss   = loss_fn(y_pred, yb)\n",
    "    \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "        if epoch % 1 == 0:\n",
    "            print(epoch, \"loss=\", loss)\n",
    "            losses_list.append(  loss  )\n",
    "            \n",
    "    return losses_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss= tensor(0.0120, grad_fn=<NllLossBackward0>)\n",
      "1 loss= tensor(0.0102, grad_fn=<NllLossBackward0>)\n",
      "2 loss= tensor(0.0063, grad_fn=<NllLossBackward0>)\n",
      "3 loss= tensor(0.0006, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = Classifier6() # create our model\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr = learning_rate) # optimizer that does steps\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # type of loss func\n",
    "\n",
    "my_losses_list = training_loop(num_epochs, model, loss_fn, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.989900\n",
      "Confusion Matrix:\n",
      "[[ 974    1    0    0    0    2    2    0    0    0]\n",
      " [   0 1087    2    0    0    0    0    3    1    0]\n",
      " [   2    0 1003    0    0    0    1    1    2    1]\n",
      " [   0    0    2 1059    0    1    0    2    1    1]\n",
      " [   1    0    0    0  963    0    4    1    1    9]\n",
      " [   0    0    0    4    0  954    3    0    0    2]\n",
      " [   0    1    0    0    1    1  977    0    0    0]\n",
      " [   0    2    4    1    0    0    0 1012    1    2]\n",
      " [   1    3    0    0    2    7    5    0  917    6]\n",
      " [   1    0    0    2    5    0    0    4    2  953]]\n",
      "Precision: 0.990\n",
      "Recall: 0.990\n",
      "F1-mesure: 0.990\n",
      "Accuracy: 0.990500\n",
      "Confusion Matrix:\n",
      "[[182   0   0   0   0   0   1   0   0   0]\n",
      " [  0 218   0   0   0   0   0   0   0   0]\n",
      " [  0   0 199   0   0   0   0   1   1   0]\n",
      " [  0   0   0 187   0   0   0   0   0   0]\n",
      " [  0   0   0   0 198   0   0   1   0   1]\n",
      " [  0   0   0   1   0 183   0   0   2   0]\n",
      " [  0   0   0   0   0   0 193   0   0   0]\n",
      " [  0   1   1   0   0   0   0 218   0   2]\n",
      " [  0   0   0   0   0   0   0   2 194   1]\n",
      " [  0   0   0   0   2   1   0   1   0 209]]\n",
      "Precision: 0.991\n",
      "Recall: 0.991\n",
      "F1-mesure: 0.990\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # detach grad tracking for tensors\n",
    "    for x_real, y_real in test_dl:\n",
    "        y_pred = model(  x_real  )\n",
    "        \n",
    "        vals, indeces = torch.max( y_pred, dim=1  )\n",
    "        preds = indeces\n",
    "        print_metrics_function(y_real, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/10, Train Loss: 0.1404\n",
      "Epoch 2/10, Train Loss: 0.0448\n",
      "Epoch 3/10, Train Loss: 0.0309\n",
      "Epoch 4/10, Train Loss: 0.0217\n",
      "Epoch 5/10, Train Loss: 0.0180\n",
      "Epoch 6/10, Train Loss: 0.0130\n",
      "Epoch 7/10, Train Loss: 0.0108\n",
      "Epoch 8/10, Train Loss: 0.0105\n",
      "Epoch 9/10, Train Loss: 0.0086\n",
      "Epoch 10/10, Train Loss: 0.0077\n",
      "Validation Accuracy: 99.03%\n",
      "Fold 2/5\n",
      "Epoch 1/10, Train Loss: 0.1347\n",
      "Epoch 2/10, Train Loss: 0.0443\n",
      "Epoch 3/10, Train Loss: 0.0294\n",
      "Epoch 4/10, Train Loss: 0.0233\n",
      "Epoch 5/10, Train Loss: 0.0173\n",
      "Epoch 6/10, Train Loss: 0.0148\n",
      "Epoch 7/10, Train Loss: 0.0108\n",
      "Epoch 8/10, Train Loss: 0.0105\n",
      "Epoch 9/10, Train Loss: 0.0088\n",
      "Epoch 10/10, Train Loss: 0.0071\n",
      "Validation Accuracy: 98.78%\n",
      "Fold 3/5\n",
      "Epoch 1/10, Train Loss: 0.1357\n",
      "Epoch 2/10, Train Loss: 0.0445\n",
      "Epoch 3/10, Train Loss: 0.0300\n",
      "Epoch 4/10, Train Loss: 0.0210\n",
      "Epoch 5/10, Train Loss: 0.0171\n",
      "Epoch 6/10, Train Loss: 0.0136\n",
      "Epoch 7/10, Train Loss: 0.0126\n",
      "Epoch 8/10, Train Loss: 0.0086\n",
      "Epoch 9/10, Train Loss: 0.0096\n",
      "Epoch 10/10, Train Loss: 0.0071\n",
      "Validation Accuracy: 98.91%\n",
      "Fold 4/5\n",
      "Epoch 1/10, Train Loss: 0.1409\n",
      "Epoch 2/10, Train Loss: 0.0442\n",
      "Epoch 3/10, Train Loss: 0.0295\n",
      "Epoch 4/10, Train Loss: 0.0213\n",
      "Epoch 5/10, Train Loss: 0.0169\n",
      "Epoch 6/10, Train Loss: 0.0139\n",
      "Epoch 7/10, Train Loss: 0.0118\n",
      "Epoch 8/10, Train Loss: 0.0088\n",
      "Epoch 9/10, Train Loss: 0.0085\n",
      "Epoch 10/10, Train Loss: 0.0066\n",
      "Validation Accuracy: 99.02%\n",
      "Fold 5/5\n",
      "Epoch 1/10, Train Loss: 0.1410\n",
      "Epoch 2/10, Train Loss: 0.0487\n",
      "Epoch 3/10, Train Loss: 0.0316\n",
      "Epoch 4/10, Train Loss: 0.0250\n",
      "Epoch 5/10, Train Loss: 0.0192\n",
      "Epoch 6/10, Train Loss: 0.0159\n",
      "Epoch 7/10, Train Loss: 0.0116\n",
      "Epoch 8/10, Train Loss: 0.0107\n",
      "Epoch 9/10, Train Loss: 0.0104\n",
      "Epoch 10/10, Train Loss: 0.0089\n",
      "Validation Accuracy: 98.99%\n",
      "Average Validation Accuracy over 5 folds: 98.95%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def k_fold_valid(model_class, train_dataloader, num_folds=5, num_epochs=10, batch_size=32):\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "    \n",
    "    # Placeholder to store results from each fold\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataloader.dataset)):\n",
    "        print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "\n",
    "        # Split the DataLoader dataset into training and validation sets for this fold\n",
    "        # Create subsets for training and validation by selecting indices from the DataLoader\n",
    "        train_subset = torch.utils.data.Subset(train_dataloader.dataset, train_idx)\n",
    "        val_subset = torch.utils.data.Subset(train_dataloader.dataset, val_idx)\n",
    "\n",
    "        # Create new DataLoaders for each fold\n",
    "        train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Initialize the model and optimizer\n",
    "        model = model_class()  # Instantiate the model class\n",
    "        criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimizer\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()  # Set the model to training mode\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            avg_train_loss = running_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}\")\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = correct / total\n",
    "        print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "        fold_results.append(val_accuracy)\n",
    "\n",
    "    # Calculate and display the average validation accuracy\n",
    "    avg_accuracy = sum(fold_results) / num_folds\n",
    "    print(f\"Average Validation Accuracy over {num_folds} folds: {avg_accuracy * 100:.2f}%\")\n",
    "\n",
    "k_fold_valid(\n",
    "    model_class = Classifier6, \n",
    "    train_dataloader = mnist_train,\n",
    "    num_folds = 5,\n",
    "    num_epochs = 10,\n",
    "    batch_size = batch_size\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-cross valid results\n",
    "Fold 1/5\n",
    "Epoch 1/10, Train Loss: 0.1384\n",
    "Epoch 2/10, Train Loss: 0.0435\n",
    "Epoch 3/10, Train Loss: 0.0298\n",
    "Epoch 4/10, Train Loss: 0.0220\n",
    "Epoch 5/10, Train Loss: 0.0162\n",
    "Epoch 6/10, Train Loss: 0.0132\n",
    "Epoch 7/10, Train Loss: 0.0112\n",
    "Epoch 8/10, Train Loss: 0.0096\n",
    "Epoch 9/10, Train Loss: 0.0086\n",
    "Epoch 10/10, Train Loss: 0.0070\n",
    "Validation Accuracy: 98.91%\n",
    "Fold 2/5\n",
    "Epoch 1/10, Train Loss: 0.1336\n",
    "Epoch 2/10, Train Loss: 0.0427\n",
    "Epoch 3/10, Train Loss: 0.0308\n",
    "Epoch 4/10, Train Loss: 0.0206\n",
    "Epoch 5/10, Train Loss: 0.0173\n",
    "Epoch 6/10, Train Loss: 0.0138\n",
    "Epoch 7/10, Train Loss: 0.0112\n",
    "Epoch 8/10, Train Loss: 0.0078\n",
    "Epoch 9/10, Train Loss: 0.0099\n",
    "Epoch 10/10, Train Loss: 0.0087\n",
    "Validation Accuracy: 98.85%\n",
    "Fold 3/5\n",
    "Epoch 1/10, Train Loss: 0.1387\n",
    "Epoch 2/10, Train Loss: 0.0465\n",
    "Epoch 3/10, Train Loss: 0.0318\n",
    "Epoch 4/10, Train Loss: 0.0214\n",
    "Epoch 5/10, Train Loss: 0.0175\n",
    "Epoch 6/10, Train Loss: 0.0148\n",
    "Epoch 7/10, Train Loss: 0.0120\n",
    "Epoch 8/10, Train Loss: 0.0110\n",
    "Epoch 9/10, Train Loss: 0.0074\n",
    "Epoch 10/10, Train Loss: 0.0100\n",
    "Validation Accuracy: 99.22%\n",
    "Fold 4/5\n",
    "Epoch 1/10, Train Loss: 0.1346\n",
    "Epoch 2/10, Train Loss: 0.0437\n",
    "Epoch 3/10, Train Loss: 0.0314\n",
    "Epoch 4/10, Train Loss: 0.0212\n",
    "Epoch 5/10, Train Loss: 0.0175\n",
    "Epoch 6/10, Train Loss: 0.0143\n",
    "Epoch 7/10, Train Loss: 0.0122\n",
    "Epoch 8/10, Train Loss: 0.0093\n",
    "Epoch 9/10, Train Loss: 0.0082\n",
    "Epoch 10/10, Train Loss: 0.0082\n",
    "Validation Accuracy: 98.90%\n",
    "Fold 5/5\n",
    "Epoch 1/10, Train Loss: 0.1428\n",
    "Epoch 2/10, Train Loss: 0.0490\n",
    "Epoch 3/10, Train Loss: 0.0321\n",
    "Epoch 4/10, Train Loss: 0.0238\n",
    "Epoch 5/10, Train Loss: 0.0196\n",
    "Epoch 6/10, Train Loss: 0.0146\n",
    "Epoch 7/10, Train Loss: 0.0129\n",
    "Epoch 8/10, Train Loss: 0.0117\n",
    "Epoch 9/10, Train Loss: 0.0095\n",
    "Epoch 10/10, Train Loss: 0.0080\n",
    "Validation Accuracy: 98.87%\n",
    "Average Validation Accuracy over 5 folds: 98.95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"team6_final_weights.pth\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2])\n",
      "tensor([6])\n",
      "tensor([3])\n",
      "tensor([2])\n",
      "tensor([0])\n",
      "tensor([2])\n",
      "tensor([3])\n",
      "tensor([2])\n",
      "tensor([8])\n",
      "tensor([4])\n"
     ]
    }
   ],
   "source": [
    "# test handwritten digits\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the image, replace with custom file path\n",
    "image_path = [\n",
    "    \"C:/Users/aaron/Digit-Classification/handwritten digits/0.png\",\n",
    "    \"C:/Users/aaron/Digit-Classification/handwritten digits/1.png\",\n",
    "    \"C:/Users/aaron/Digit-Classification/handwritten digits/2.png\",\n",
    "    \"C:/Users/aaron/Digit-Classification/handwritten digits/3.png\",\n",
    "    \"C:/Users/aaron/Digit-Classification/handwritten digits/4.png\",\n",
    "    \"C:/Users/aaron/Digit-Classification/handwritten digits/5.png\",\n",
    "    \"C:/Users/aaron/Digit-Classification/handwritten digits/6.png\",\n",
    "    \"C:/Users/aaron/Digit-Classification/handwritten digits/7.png\",\n",
    "    \"C:/Users/aaron/Digit-Classification/handwritten digits/8.png\",\n",
    "    \"C:/Users/aaron/Digit-Classification/handwritten digits/9.png\"\n",
    "]  \n",
    "for path in image_path:\n",
    "    image = Image.open(path)\n",
    "\n",
    "    # convert to greyscale & resize\n",
    "    image = image.convert(\"L\")\n",
    "    image = image.resize((28,28))\n",
    "\n",
    "    # convert to tensor\n",
    "    transform = transforms.ToTensor()\n",
    "    image_tr = transform(image)\n",
    "    image_tr = image_tr.unsqueeze(dim=0) # add batch dimension\n",
    "\n",
    "    pred = model(image_tr)\n",
    "    vals, indeces = torch.max( pred, dim=1  )\n",
    "    preds = indeces\n",
    "    print(preds)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
